{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n",
      "Downloading: 100%|██████████| 480/480 [00:00<00:00, 480kB/s]\n",
      "Downloading: 100%|██████████| 465M/465M [00:23<00:00, 20.4MB/s] \n",
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n",
      "Downloading: 100%|██████████| 878k/878k [00:01<00:00, 719kB/s]  \n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 465kB/s]  \n",
      "Downloading: 100%|██████████| 1.29M/1.29M [00:01<00:00, 961kB/s] \n"
     ]
    }
   ],
   "source": [
    "# 가려진 부분을 채워넣기\n",
    "nlp = pipeline(\"fill-mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizza is my <mask>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = f\"Pizza is my {nlp.tokenizer.mask_token}\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.07068377733230591,\n",
       "  'token': 2674,\n",
       "  'token_str': ' favorite',\n",
       "  'sequence': 'Pizza is my favorite'},\n",
       " {'score': 0.0355093739926815,\n",
       "  'token': 4592,\n",
       "  'token_str': ' lunch',\n",
       "  'sequence': 'Pizza is my lunch'},\n",
       " {'score': 0.03522920608520508,\n",
       "  'token': 8492,\n",
       "  'token_str': ' cake',\n",
       "  'sequence': 'Pizza is my cake'},\n",
       " {'score': 0.026076242327690125,\n",
       "  'token': 9366,\n",
       "  'token_str': ' pizza',\n",
       "  'sequence': 'Pizza is my pizza'},\n",
       " {'score': 0.02567906863987446,\n",
       "  'token': 17927,\n",
       "  'token_str': ' dessert',\n",
       "  'sequence': 'Pizza is my dessert'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.07517623156309128,\n",
       "   'token': 95,\n",
       "   'token_str': ' just',\n",
       "   'sequence': '<s>Pizza is just my<mask> food</s>'},\n",
       "  {'score': 0.06924442946910858,\n",
       "   'token': 122,\n",
       "   'token_str': ' now',\n",
       "   'sequence': '<s>Pizza is now my<mask> food</s>'},\n",
       "  {'score': 0.06733357906341553,\n",
       "   'token': 460,\n",
       "   'token_str': ' always',\n",
       "   'sequence': '<s>Pizza is always my<mask> food</s>'},\n",
       "  {'score': 0.05711856484413147,\n",
       "   'token': 1153,\n",
       "   'token_str': ' probably',\n",
       "   'sequence': '<s>Pizza is probably my<mask> food</s>'},\n",
       "  {'score': 0.05621125549077988,\n",
       "   'token': 8127,\n",
       "   'token_str': ' NOT',\n",
       "   'sequence': '<s>Pizza is NOT my<mask> food</s>'}],\n",
       " [{'score': 0.5211484432220459,\n",
       "   'token': 2674,\n",
       "   'token_str': ' favorite',\n",
       "   'sequence': '<s>Pizza is<mask> my favorite food</s>'},\n",
       "  {'score': 0.19279128313064575,\n",
       "   'token': 5863,\n",
       "   'token_str': ' comfort',\n",
       "   'sequence': '<s>Pizza is<mask> my comfort food</s>'},\n",
       "  {'score': 0.15253256261348724,\n",
       "   'token': 5548,\n",
       "   'token_str': ' favourite',\n",
       "   'sequence': '<s>Pizza is<mask> my favourite food</s>'},\n",
       "  {'score': 0.011001464910805225,\n",
       "   'token': 7080,\n",
       "   'token_str': ' breakfast',\n",
       "   'sequence': '<s>Pizza is<mask> my breakfast food</s>'},\n",
       "  {'score': 0.009597652591764927,\n",
       "   'token': 15163,\n",
       "   'token_str': ' junk',\n",
       "   'sequence': '<s>Pizza is<mask> my junk food</s>'}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = f\"Pizza is {nlp.tokenizer.mask_token} my {nlp.tokenizer.mask_token} food\"\n",
    "nlp(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForMaskedLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "id2word = {i:word for word,i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizza is my <mask> food'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = f\"Pizza is my {tokenizer.mask_token} food\"\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=int32, numpy=array([[    0,   510, 35280,    16,   127, 50264,   689,     2]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=bool, numpy=array([False, False, False, False, False,  True, False, False])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0] == tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_indices = tf.where(input_ids[0] == tokenizer.mask_token_id)[0].numpy().tolist()\n",
    "mask_token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(input_ids)\n",
    "logits = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = mask_token_indices[0]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 8, 50265])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50265,), dtype=float32, numpy=\n",
       "array([-2.8974793 , -4.8479943 ,  3.5865424 , ..., -4.247888  ,\n",
       "       -4.94939   , -0.17405021], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_logits = logits[0,i,:]\n",
    "mask_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TopKV2(values=<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.242867 , 16.955906 , 16.14506  , 13.9436865, 13.821488 ,\n",
       "       13.255374 , 13.070421 , 12.692704 , 12.688813 , 12.608028 ],\n",
       "      dtype=float32)>, indices=<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
       "array([ 2674,  5863,  5548,  3366,  6543,  6813,  7080, 17771, 15163,\n",
       "        5440])>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top  = tf.math.top_k(mask_token_logits, k = 10)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ġfavorite\n",
      "Ġcomfort\n",
      "Ġfavourite\n",
      "Ġdream\n",
      "Ġsignature\n",
      "Ġpreferred\n",
      "Ġbreakfast\n",
      "Ġstaple\n",
      "Ġjunk\n",
      "Ġpassion\n"
     ]
    }
   ],
   "source": [
    "for i in top.indices.numpy().tolist():\n",
    "    print(id2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sequence = f\"Pizza {tokenizer.mask_token} my {tokenizer.mask_token} food\"\n",
    "input_ids = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "mask_token_indices = tf.where(input_ids[0] == tokenizer.mask_token_id)\n",
    "mask_token_indices = tf.squeeze(mask_token_indices).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===3===\n",
      "Ġis,Ġwith,Ġdelivers,Ġand,Ġfor,:,Ġmakes,Ġserves,Ġ&,Ġtastes,\n",
      "===5===\n",
      "Ġfavorite,Ġfavourite,Ġcomfort,Ġjunk,Ġbreakfast,Ġlunch,Ġown,Ġsnack,Ġdog,Ġfried,\n"
     ]
    }
   ],
   "source": [
    "result = model(input_ids)\n",
    "logits = result[0]\n",
    "for i in mask_token_indices:\n",
    "    print(f\"==={i}===\")\n",
    "    mask_token_logits = logits[0,i,:]\n",
    "    top = tf.math.top_k(mask_token_logits, k = 10)\n",
    "    for i in top.indices.numpy().tolist():\n",
    "        print(id2word[i],end = \",\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFMaskedLMOutput(loss=None, logits=<tf.Tensor: shape=(1, 8, 50265), dtype=float32, numpy=\n",
       "array([[[33.688335  , -5.1455574 , 20.612871  , ...,  0.273535  ,\n",
       "          2.7475054 , 12.919054  ],\n",
       "        [ 1.9103746 , -5.8146024 , 16.06207   , ..., -1.8897159 ,\n",
       "         -0.8535603 ,  1.0776864 ],\n",
       "        [ 2.9016135 , -5.552311  ,  8.874351  , ..., -5.091152  ,\n",
       "         -2.465067  ,  1.0359651 ],\n",
       "        ...,\n",
       "        [-3.8873408 , -5.239915  ,  3.279696  , ..., -6.045577  ,\n",
       "         -6.1138377 , -0.86565375],\n",
       "        [-3.0044525 , -6.6731157 ,  7.363603  , ..., -4.8081956 ,\n",
       "         -5.0538235 , -2.0836086 ],\n",
       "        [15.128035  , -6.6216936 , 21.003073  , ..., -3.602645  ,\n",
       "         -1.8064204 ,  5.267201  ]]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83d3e1d533d06a5ed13bdd408cfdbe5752516a627e355ce33664633b6ff4534e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
